#!/usr/bin/env python

import re
import sys
from lxml import html
import requests


def parseWebContent(url: str, regex_str: str, xpath_expr: str):
    result = None

    # Compile the regular expression from string
    regex = re.compile(regex_str)

    # Invoke a new HTTP GET request
    response = requests.get(url)
    html_content = html.fromstring(response.content)

    #  Find all the elements that were captured the xpath expression
    elements = html_content.xpath(xpath_expr)

    for e in elements:
        # If you want the text content of the element:
        # print(element.text_content())
        # If you want the HTML representation of the element:
        v = html.tostring(e).decode()

        matches = regex.search(v)

        if matches:
            result = matches.group(1)

    print(result)
# end of parseWebContent

# Allow the user to pass in the arguments
argv = sys.argv
parseWebContent(argv[0], argv[1], argv[2])

# # This is how it should be used
# parseWebContent(
#     'https://www.tweaking4all.com/home-theatre/rename-my-tv-series-v2/',
#     'RenameMyTVSeries-([\\d.]+)-Linux64bit\\.tar\\.gz',
#     '//div[@class="alert alert-success"]/table/tr/td[contains(text(),"RenameMyTVSeries")]',
# )

# # This is how it should be used in cli
# ./scrape_website 'https://www.tweaking4all.com/home-theatre/rename-my-tv-series-v2/' 'RenameMyTVSeries-([\\d.]+)-Linux64bit\\.tar\\.gz' '//div[@class="alert alert-success"]/table/tr/td[contains(text(),"RenameMyTVSeries")]'
